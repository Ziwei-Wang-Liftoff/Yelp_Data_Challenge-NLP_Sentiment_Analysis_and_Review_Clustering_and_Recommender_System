{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp_Data_Challenge - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main tasks\n",
    "\n",
    "1. Data preprocessing\n",
    "    - 1.1 Define feature variables\n",
    "    - 1.2 Define target variable\n",
    "    - 1.3 Create training dataset and test dataset\n",
    "    - 1.4 Get NLP representation of the documents\n",
    "2. Cluster reviews with KMeans\n",
    "    - 2.1 Fit k-means clustering with the training vectors and apply it on all the data\n",
    "    - 2.2 Make predictions on all data\n",
    "    - 2.3 Inspect the centroids\n",
    "    - 2.4 Try using different k (clusters)\n",
    "3. Cluster all the reviews of the most reviewed restaurant\n",
    "    - 3.1 Vectorize the text feature\n",
    "    - 3.2 Define target variable\n",
    "    - 3.3 Create train and test datasets\n",
    "    - 3.4 Get NLP representation of the documents\n",
    "    - 3.5 Cluster reviews with KMeans\n",
    "4. Other user cases of clustering\n",
    "    - 4.1 Different distance/similarity metrics for clusterings\n",
    "    - 4.2 Cluster restaurants by category information\n",
    "    - 4.3 Cluster restaurants by restaurant names\n",
    "    - 4.4 Cluster restaurants by tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/last_2_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>6SgvNWJltnZhW7duJgZ42w</td>\n",
       "      <td>5</td>\n",
       "      <td>This is mine and my fiancé's favorite steakhou...</td>\n",
       "      <td>0</td>\n",
       "      <td>oFyOUOeGTRZhFPF9uTqrTQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>0</td>\n",
       "      <td>UxFpgng8dPMWOj99653k5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>Truly Fantastic!  Best Steak ever. Service was...</td>\n",
       "      <td>0</td>\n",
       "      <td>aVOGlN9fZ-BXcbtj6dbf0g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>Xp3ppynEvVu1KxDHQ3ae8w</td>\n",
       "      <td>5</td>\n",
       "      <td>Delmonico Steakhouse is a steakhouse owned by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>KC8H7qTZVPIEnanw9fG43g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>LEzphAnz0vKE32PUCbjLgQ</td>\n",
       "      <td>4</td>\n",
       "      <td>One of the top steak places I've had in Vegas ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3RTesI_MAwct13LWm4rhLw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>['Cajun/Creole', 'Steakhouses', 'Restaurants']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>0</td>\n",
       "      <td>4e-cxYVdlIu2ZDxVJqUfOQ</td>\n",
       "      <td>5</td>\n",
       "      <td>This place is superb from the customer service...</td>\n",
       "      <td>0</td>\n",
       "      <td>EAOt1UQhJD0GG3l_jv7rWA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                      categories  \\\n",
       "0  Delmonico Steakhouse  ['Cajun/Creole', 'Steakhouses', 'Restaurants']   \n",
       "1  Delmonico Steakhouse  ['Cajun/Creole', 'Steakhouses', 'Restaurants']   \n",
       "2  Delmonico Steakhouse  ['Cajun/Creole', 'Steakhouses', 'Restaurants']   \n",
       "3  Delmonico Steakhouse  ['Cajun/Creole', 'Steakhouses', 'Restaurants']   \n",
       "4  Delmonico Steakhouse  ['Cajun/Creole', 'Steakhouses', 'Restaurants']   \n",
       "\n",
       "   avg_stars  cool        date  funny               review_id  stars  \\\n",
       "0        4.0     0  2016-03-31      0  6SgvNWJltnZhW7duJgZ42w      5   \n",
       "1        4.0     0  2016-02-10      0  UxFpgng8dPMWOj99653k5Q      5   \n",
       "2        4.0     0  2017-02-14      0  Xp3ppynEvVu1KxDHQ3ae8w      5   \n",
       "3        4.0     1  2017-05-28      0  LEzphAnz0vKE32PUCbjLgQ      4   \n",
       "4        4.0     0  2017-08-25      0  4e-cxYVdlIu2ZDxVJqUfOQ      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  This is mine and my fiancé's favorite steakhou...       0   \n",
       "1  Truly Fantastic!  Best Steak ever. Service was...       0   \n",
       "2  Delmonico Steakhouse is a steakhouse owned by ...       0   \n",
       "3  One of the top steak places I've had in Vegas ...       2   \n",
       "4  This place is superb from the customer service...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  oFyOUOeGTRZhFPF9uTqrTQ  \n",
       "1  aVOGlN9fZ-BXcbtj6dbf0g  \n",
       "2  KC8H7qTZVPIEnanw9fG43g  \n",
       "3  3RTesI_MAwct13LWm4rhLw  \n",
       "4  EAOt1UQhJD0GG3l_jv7rWA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Filter positive reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I am only interested in perfect (5 stars) rating reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df[df['stars'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210559"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here feautre variable is the text of the review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents = df_positive['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210559\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: documents\n",
    "# Y: targets\n",
    "# Now split the data to training set 80% and test set 20%\n",
    "documents_train, documents_test = train_test_split(documents, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168447, 42112)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_train), len(documents_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Get NLP representation of the documents\n",
    "\n",
    "#### Fit TfidfVectorizer with training data only, then tranform all the data to tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer\n",
    "# choose a reasonable max_features, e.g. 1000 to fast the computation speed\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with your training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168447, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to transform all the reviews\n",
    "vectors_documents = vectorizer.transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Cluster reviews with KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fit k-means clustering with the training vectors and apply it on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=8, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans()\n",
    "\n",
    "kmeans.fit(vectors_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Make predictions on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_cluster = kmeans.predict(vectors_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Inspect the centroids\n",
    "\n",
    "- Description: To find out what \"topics\" Kmeans has discovered we must inspect the centroids. Print out the centroids of the Kmeans clustering. These centroids are simply a bunch of vectors.  To make sense of them we need to map these vectors back into our 'word space'.  Think of each feature/dimension of the centroid vector as representing the \"average\" review or the average occurances of words for that cluster.\n",
    "- Solution: Find the top 10 features (words) within each cluster. \n",
    "- Steps: \n",
    "    - (1) Sort each centroid vector to find the top 10 features \n",
    "    - (2) Go back to our vectorizer object to find out what words each of these features corresponds to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clusters:(8, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Default of kmeans uses 8 clusters\n",
    "print ('number of clusters:' + str(kmeans.cluster_centers_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 features for each cluster:\n",
      "0: burger, fries, burgers, good, great, place, cheese, best, shake, food\n",
      "1: food, good, place, best, vegas, amazing, delicious, time, service, just\n",
      "2: excellent, service, food, great, place, good, vegas, definitely, restaurant, best\n",
      "3: love, place, food, great, good, service, amazing, best, friendly, staff\n",
      "4: pizza, great, crust, place, good, best, vegas, cheese, service, delicious\n",
      "5: great, food, service, place, amazing, good, awesome, friendly, staff, definitely\n",
      "6: sushi, place, roll, rolls, great, fresh, ayce, service, best, fish\n",
      "7: chicken, fried, good, food, rice, place, delicious, great, ordered, amazing\n"
     ]
    }
   ],
   "source": [
    "# print top 10 words of each cluster centers\n",
    "# step (1) Sort each centroid vector to find the top 10 features\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:, -1:-11:-1]\n",
    "print(\"top 10 features for each cluster:\")\n",
    "# step (2) Go back to our vectorizer object to find out what words each of these features corresponds to\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \", \".join(words[i] for i in centroid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will try different k, because:\n",
    "    - Using eight clusters (default setting in kmeans), I found that several clusters are kind of similar to each other, such as in Cluster 0 and 7 might signify fast food restaurants. \n",
    "    - The rest of clusters have some significant meanings such as in Cluster 6, it mainly tell about Japanese restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Try using different k (clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the top features change after using 5 clusters?\n",
    "- Using five clusters, the difference among clusters stands out more significant than using eight clusters. Each cluster now has an unique topic, such as Cluster 0 is surrounding with the topic of chicken, Cluster 2 is relating to Japanese food, Cluster 3 is relating to the pizza, and Cluster 4 is mainly about service aspect in vegas.\n",
    "- However, the top features using five clusters seem to be highly overlapped with the default method. In fact, it's a good strategy to narrow down overlapped clusters into denser clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 features for each cluster:\n",
      "0: good,food,really,place,service,great,nice,love,chicken,time\n",
      "1: place,food,best,vegas,delicious,amazing,time,love,ve,just\n",
      "2: sushi,place,roll,rolls,great,fresh,ayce,service,best,fish\n",
      "3: pizza,great,place,crust,good,best,love,service,vegas,cheese\n",
      "4: great,food,service,place,amazing,awesome,friendly,excellent,staff,definitely\n"
     ]
    }
   ],
   "source": [
    "# Find the top 10 features for each cluster.\n",
    "kmeans = KMeans(n_clusters = 5)\n",
    "kmeans.fit(vectors_train)\n",
    "assigned_cluster = kmeans.predict(vectors_documents)\n",
    "\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:, -1:-11:-1]\n",
    "print(\"top 10 features for each cluster:\")\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \",\".join(words[i] for i in centroid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the rating and review of a random sample of the reviews assigned to each cluster to get a sense of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "    My friends and I come here every Friday! It is our tradition. :) We love Sushi Kaya for many, many reasons. Their sushi is so fresh and cold. We usually do all-you-can-eat, and start off with miso soup and seaweed salad. I love their spicy tuna, sashimi, yellowtail, and albacore. They have a nice fish-to-rice too ratio since some places give way too much rice! I love their mochi as a dessert. The service is usually great every time. It doesn't take long when we order for our AYCE sushi.\n",
      "\n",
      "This place gets packed on the weekends, and for good reason! I would wait the 20 minutes or make it easier for yourself, and call ahead of time to make reservations.\n",
      "cluster 1:\n",
      "    Oh how I miss Hawaii after coming here! If you're looking for good and cheap food, this is the place to be. We ordered a furikake chicken and that was more than enough for two people. We had a ton of leftover. The chicken has so much flavor! We also ordered a half order of avocado poke and it was just enough for me. The poke was good but didn't taste as fresh. Maybe I ordered the wrong flavor. I definitely want to try the shoyu or sesame poke next time. Anyways this place is delicious and gives huge portions so you can't go wrong with that.\n",
      "cluster 2:\n",
      "    Salad was amazing. The gyro had an excellent combination and balance. I could eat here every day\n",
      "cluster 3:\n",
      "    Awesome to finally have a Robertos on this side of shit\n",
      "Summerlin.   The downfall is the weekends, uber crowded, ordered 1 burrito and it took about 30 minutes.  Dining room was packed for people waiting on To go orders,  drive through was packed and people were coming in from the drive through inside asking where there orders were.  Long story short, good food, be prepared to wait.  I will count this as a new weekend, everyone wants to get some Robertos and a apartment community is next to it.\n",
      "cluster 4:\n",
      "    I was so excited to eat here. As I enjoy the clam chowder very much. However, it was not the case this time. \n",
      "\n",
      "The clam chowder was soooooooo bland. I don't know if it was sitting out too long. We ordered the crab cakes, too. What the heck?! This time they were so slim and small (see my pic)- sheesh, $13! They were plumper the last time. \n",
      "\n",
      "My husband was looking forward to the diablo pasta... no longer available so he ordered gumbo. He said it was okay. \n",
      "\n",
      "\n",
      "We will check out other recommended places in the comments and will NOT be returning here. That's too bad.\n"
     ]
    }
   ],
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    cluster = np.arange(0, vectors_documents.shape[0])[assigned_cluster==i]\n",
    "    sample_reviews = np.random.choice(cluster, 1, replace=False)\n",
    "    print(\"cluster %d:\" % i)\n",
    "    for review in sample_reviews:\n",
    "        print(\"    %s\" % df.loc[review]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cluster all the reviews of the most reviewed restaurant\n",
    "- 3.1 Vectorize the text feature\n",
    "- 3.2 Define the target variable\n",
    "- 3.3 Create train and test datasets\n",
    "- 3.4 Get NLP representation of the documents\n",
    "- 3.5 Cluster reviews with KMean\n",
    "\n",
    "#### Let's find the most reviewed restaurant and analyze its reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hash House A Go Go'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the business who got most reviews, get your filtered df, name it df_top_restaurant\n",
    "df_top_restaurant = df['name'].value_counts().index[0]\n",
    "df_top_restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also load restaurant profile information from the business dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32737</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>['American (New)', 'Restaurants', 'Breakfast &amp;...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-22</td>\n",
       "      <td>0</td>\n",
       "      <td>psGDwACpn7tFmWm36865fA</td>\n",
       "      <td>4</td>\n",
       "      <td>There isn't much here for vegetarians, but I h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Y76nS3L426UCz7N_1pUfUQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32738</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>['American (New)', 'Restaurants', 'Breakfast &amp;...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>0</td>\n",
       "      <td>ZY0ym6jDPXCnyzyRKSVTHg</td>\n",
       "      <td>4</td>\n",
       "      <td>Visiting Las Vegas again, and decided to stop ...</td>\n",
       "      <td>0</td>\n",
       "      <td>SeHCNZeTtVvL1HmKFOLSkQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32739</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>['American (New)', 'Restaurants', 'Breakfast &amp;...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>0</td>\n",
       "      <td>vPFRrO6k6ynH-CgGKJLpPQ</td>\n",
       "      <td>5</td>\n",
       "      <td>This place is as crazy as Las Vegas.  The twis...</td>\n",
       "      <td>0</td>\n",
       "      <td>SvpxzDdYOrrI9ntolyNSxQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32740</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>['American (New)', 'Restaurants', 'Breakfast &amp;...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-26</td>\n",
       "      <td>0</td>\n",
       "      <td>DOZWVKN2n4CAp7mtkhxiaw</td>\n",
       "      <td>1</td>\n",
       "      <td>I've eaten at Hash House A Go Go on the strip ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Io0qqdu_PyKfkr8d7F19mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32741</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>['American (New)', 'Restaurants', 'Breakfast &amp;...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-UGGkrLKjWMdW2N9l2rb2Q</td>\n",
       "      <td>4</td>\n",
       "      <td>We were told that this was a good place for br...</td>\n",
       "      <td>0</td>\n",
       "      <td>JrILFVrSIRIacx2qTy5tiA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                name  \\\n",
       "0  32737  Hash House A Go Go   \n",
       "1  32738  Hash House A Go Go   \n",
       "2  32739  Hash House A Go Go   \n",
       "3  32740  Hash House A Go Go   \n",
       "4  32741  Hash House A Go Go   \n",
       "\n",
       "                                          categories  avg_stars  cool  \\\n",
       "0  ['American (New)', 'Restaurants', 'Breakfast &...        3.5     0   \n",
       "1  ['American (New)', 'Restaurants', 'Breakfast &...        3.5     0   \n",
       "2  ['American (New)', 'Restaurants', 'Breakfast &...        3.5     0   \n",
       "3  ['American (New)', 'Restaurants', 'Breakfast &...        3.5     0   \n",
       "4  ['American (New)', 'Restaurants', 'Breakfast &...        3.5     1   \n",
       "\n",
       "         date  funny               review_id  stars  \\\n",
       "0  2016-06-22      0  psGDwACpn7tFmWm36865fA      4   \n",
       "1  2017-06-19      0  ZY0ym6jDPXCnyzyRKSVTHg      4   \n",
       "2  2017-01-13      0  vPFRrO6k6ynH-CgGKJLpPQ      5   \n",
       "3  2015-08-26      0  DOZWVKN2n4CAp7mtkhxiaw      1   \n",
       "4  2017-10-16      0  -UGGkrLKjWMdW2N9l2rb2Q      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  There isn't much here for vegetarians, but I h...       0   \n",
       "1  Visiting Las Vegas again, and decided to stop ...       0   \n",
       "2  This place is as crazy as Las Vegas.  The twis...       0   \n",
       "3  I've eaten at Hash House A Go Go on the strip ...       0   \n",
       "4  We were told that this was a good place for br...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  Y76nS3L426UCz7N_1pUfUQ  \n",
       "1  SeHCNZeTtVvL1HmKFOLSkQ  \n",
       "2  SvpxzDdYOrrI9ntolyNSxQ  \n",
       "3  Io0qqdu_PyKfkr8d7F19mg  \n",
       "4  JrILFVrSIRIacx2qTy5tiA  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load business dataset (optional)\n",
    "# Take a look at the most reviewed restaurant's profile \n",
    "df_top_restaurant = df[df['name'] == df_top_restaurant].copy().reset_index()\n",
    "df_top_restaurant.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Vectorize the text feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3620,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents_top_restaurant\"\n",
    "documents_top_restaurant = df_top_restaurant['text'].values\n",
    "documents_top_restaurant.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again, we look at perfect (5 stars) and imperfect (1-4 stars) rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_restaurant['target'] = df_top_restaurant['stars'] == 5\n",
    "target_top_restaurant = df_top_restaurant['target'].values\n",
    "target_top_restaurant[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the statistic of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3620, 0.42265193370165743, 0.49398104886716776)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_top_restaurant), target_top_restaurant.mean(), target_top_restaurant.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: documents_top_restaurant\n",
    "# Y: target\n",
    "# Now split the data to training set 80% and test set 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    documents_top_restaurant,\n",
    "    target_top_restaurant,\n",
    "test_size = 0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with your training data\n",
    "vector_train = vectorizer.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to transform the test data\n",
    "vector_test = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to transform all the data\n",
    "vector_documents_top_restaurant = vectorizer.transform(documents_top_restaurant).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Cluster reviews with KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit k-means clustering on the training vectors and make predictions on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=4, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Fit k-means clustering on the train vectors\n",
    "\n",
    "kmeans = KMeans(n_clusters = 4)\n",
    "\n",
    "kmeans.fit(vector_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on all your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on all data\n",
    "assigned_cluster = kmeans.predict(vector_documents_top_restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the centroids and find the top 10 features for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 features for each cluster:\n",
      "0: chicken, waffles, fried, sage, bacon, benedict, good, food, place, huge\n",
      "1: food, minutes, wait, time, just, service, good, took, order, table\n",
      "2: hash, good, breakfast, food, house, eggs, pancake, place, potatoes, huge\n",
      "3: great, food, portions, place, service, huge, wait, good, vegas, amazing\n"
     ]
    }
   ],
   "source": [
    "# Find the top 10 features for each cluster.\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:, -1:-11:-1]\n",
    "print(\"top 10 features for each cluster:\")\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \", \".join(words[i] for i in centroid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "- Using four clusters, the difference among clusters stands out significantly and each cluster now has an unique topic, shows different aspects that customers care about:\n",
    "    - Cluster 0 is surrounding with the topic of food, like chicken and waffles. \n",
    "    - Cluster 1 is surrounding with the topic of waiting time and service.\n",
    "    - Cluster 2 is relating to the breakfast, like eggs and pancake. \n",
    "    - Cluster 3 is mainly about the taste and nutritional value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the rating and review of a random sample of the reviews assigned to each cluster to get a sense of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "    While being seated, I saw the popular Chicken and Waffles being delivered to a neighboring table. The presentation was so fabulous, I felt I had to try it! It was quite tasty, and HUGE! ( Share if you can, or plan on a 'to go' box if you have somewhere to keep the leftovers!) 4 good sized waffles, bacon strips layered about, and two ample boneless fried chicken breasts on top...YUM! My husband had the steel cut oatmeal with fruit so he could help me with my endeavor, but his turned out to be plentiful, also! The oatmeal had banana, apple, blueberries, and finely chopped mango on top.  The restaurant itself was spacious with a comfortable theme. There are numerous autographed menus on display of current celebrities, sports greats, & political figures...interesting to look at while you wait to get seated. Our only drawback was we felt a bit like a cattle-call as far as service. It was a bit impersonal, & my husband's oatmeal came out significantly earlier than my breakfast. He finally started eating before it got cold, with me just looking around wondering if they had forgotten mine.\n",
      "cluster 1:\n",
      "    My husband and I eat at this HH a Go-Go every time we come to Las Vegas. Their service is never a 5, but this time was just absurd. Immediately we noticed that half of the dining area was closed, for no good reason apparently. People were waiting in line to be seated, while there were clearly tables available on both sides. Okay, whatever. We got seated. It took a good 8 minutes before a busser came and took our drink order which was 2 coffees and 2 glasses of water. We got our coffee within minutes, but no water in sight. When our actual server, Marcy, finally came to take our order we asked for our waters again as well as ordering the original HH Farmhouse Benedict for myself and the Chicken and Waffles for my husband. A few minutes later the same busser returned with a water for me. Just for me though, no water for my husband. Marcy was nearly impossible to track down and when we finally got her attention and asked AGAIN for his water she seemed irritated and said okay water and walked away. My husband's chicken and Waffles arrived at the table BEFORE his water did. Finally we both had our food and were excited to be eating. This is the only reason this review has a second star. The taste was what was expected. However for the portions given, I would have expected more than one egg on my Benedict. Before even 5 minutes passes by, Marcy slams our check on our table and says \"whenever you're ready\". No \"no hurry\", or \"any dessert before I give you your tab?\" none of that. Just a rude deliverance of our bill. I felt like I was being rushed out of the restaurant when all I wanted to do was sit down and enjoy a meal. The table next to us clearly had issues with Marcy as well. My husband and I observed a girl at the table ask Marcy a question when she was right next to her, and Marcy ignored her question and walked away. This experience made me want to never return to HH A Go-Go. Or at least not to this location. And honestly, Marcy needs to work on her Service skills because she is the absolute worst.\n",
      "cluster 2:\n",
      "    How does this place have high reviews? I went here many years ago and never returned until an out of towner wanted to go. I guess if you want to be a gluttonous pig and you like mediocre food then this is the place for you. I shared an entree with my friend and I'm glad about that. Portion sizes are too big and out of control. This restaurant is too much hype in my opinion. I've been to this location and the strip location. The strip location was about one of the only restaurants we could find in the middle of the night, and it brought some real interesting folks. I enjoyed hearing drunken stories more than the food.\n",
      "cluster 3:\n",
      "    Had a great breakfast and a good time.  The wait was long and price was high but what do you expect from a popular quality place in Vegas.\n"
     ]
    }
   ],
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    cluster = np.arange(0, vector_documents_top_restaurant.shape[0])[assigned_cluster==i]\n",
    "    sample_reviews = np.random.choice(cluster, 1, replace=False)\n",
    "    print(\"cluster %d:\" % i)\n",
    "    for review in sample_reviews:\n",
    "        print(\"    %s\" % df_top_restaurant.loc[review]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Other user cases of clustering\n",
    "- 4.1 Different distance/similarity metrics for clusterings\n",
    "- 4.2 Cluster restaurants by category information\n",
    "- 4.3 Cluster restaurants by restaurant names\n",
    "- 4.4 Cluster restaurants by tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Different distance/similarity metrics for clusterings\n",
    "\n",
    "#### Q: How do you compare with Cosine distance or Euclidean distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A:\n",
    "- Cosine takes more computation time in comparison to  Euclidean distance. \n",
    "- While the “correlation” distance measures show a better interpretation of the clustered data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Cluster restaurants by category information\n",
    "**Note:** a business may have mutiple categories, e.g. a restaurant can have both \"Restaurants\" and \"Korean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((447033,), dtype('O'))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents = df['categories'].values\n",
    "documents.shape, documents.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: documents_top_restaurant\n",
    "# Y: target\n",
    "# Now split the data to training set 80% and test set 20%\n",
    "documents_train, documents_test = train_test_split(\n",
    "    documents,test_size = 0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer, choose a reasonable max_features, e.g. 1000\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 500)\n",
    "\n",
    "# Train the model with your training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train).toarray()\n",
    "\n",
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "# Use the trained model to transform all the reviews\n",
    "vectors_documents = vectorizer.transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit k-means clustering on the training vectors and make predictions on all data\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "\n",
    "kmeans.fit(vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on all data\n",
    "assigned_cluster = kmeans.predict(vectors_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 features for each cluster:\n",
      "0: restaurants, food, mexican, chinese, thai, barbeque, asian, seafood, fusion, japanese\n",
      "1: bars, nightlife, sushi, restaurants, japanese, american, wine, new, cocktail, seafood\n",
      "2: pizza, italian, restaurants, sandwiches, wings, chicken, salad, food, seafood, delis\n",
      "3: breakfast, brunch, american, restaurants, traditional, sandwiches, food, new, buffets, diners\n",
      "4: american, traditional, new, burgers, restaurants, food, steakhouses, fast, seafood, southern\n"
     ]
    }
   ],
   "source": [
    "# Find the top 10 features for each cluster.\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:, -1:-11:-1]\n",
    "print(\"top 10 features for each cluster:\")\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \", \".join(words[i] for i in centroid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "#### Cluster restaurants from their category information, the difference among clusters is significant. Each cluster now has an unique topic, such as Cluster 0 is mainly about Mexican and Chinese, Cluster 1 is Japanese, Cluster 2 is Italian,  Cluster 3 is American breakfast, and Cluster 4 is American(Traditional) in vegas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we defined the most representative restaurant as the one with most review comments in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0 representative restaurant: Gangnam Asian BBQ Dining\n",
      "cluster 1 representative restaurant: Lotus of Siam\n",
      "cluster 2 representative restaurant: Secret Pizza\n",
      "cluster 3 representative restaurant: Hash House A Go Go\n",
      "cluster 4 representative restaurant: Gordon Ramsay BurGR\n"
     ]
    }
   ],
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    cluster = df.iloc[assigned_cluster == i]\n",
    "    print(\"cluster %d representative restaurant: %s\" % (i, cluster['name'].value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Cluster restaurants by restaurant names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we cluster categories from business entities, we are trying to find the similarity between restaurant names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((447033,), dtype('O'))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents_name = df['name'].values\n",
    "documents_name.shape, documents_name.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: documents_top_restaurant\n",
    "# Y: target\n",
    "# Now split the data to training set 80% and test set 20%\n",
    "documents_name_train, documents_name_test = train_test_split(\n",
    "    documents_name,test_size = 0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer, choose a reasonable max_features, e.g. 1000\n",
    "vectorizer_name = TfidfVectorizer(stop_words = 'english', max_features = 500)\n",
    "\n",
    "# Train the model with your training data\n",
    "vectors_train_name = vectorizer_name.fit_transform(documents_train).toarray()\n",
    "\n",
    "# Get the vocab of your tfidf\n",
    "words_name = vectorizer_name.get_feature_names()\n",
    "\n",
    "# Use the trained model to transform all the reviews\n",
    "vectors_documents_name = vectorizer_name.transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit k-means clustering on the training vectors and make predictions on all data\n",
    "\n",
    "kmeans_name = KMeans(n_clusters=5)\n",
    "\n",
    "kmeans_name.fit(vectors_train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on all data\n",
    "assigned_cluster = kmeans_name.predict(vectors_documents_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 features for each cluster:\n",
      "0: restaurants, food, american, mexican, burgers, chinese, new, traditional, fast, seafood\n",
      "1: japanese, sushi, bars, restaurants, fusion, asian, ramen, noodles, seafood, poke\n",
      "2: bars, nightlife, american, restaurants, wine, new, cocktail, sports, traditional, mexican\n",
      "3: breakfast, brunch, american, restaurants, traditional, sandwiches, food, new, buffets, diners\n",
      "4: pizza, italian, restaurants, sandwiches, wings, salad, chicken, food, seafood, american\n"
     ]
    }
   ],
   "source": [
    "# Find the top 10 features for each cluster.\n",
    "top_n = 10\n",
    "top_centroids = kmeans_name.cluster_centers_.argsort()[:, -1:-(top_n+1):-1]\n",
    "print(\"top 10 features for each cluster:\")\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \", \".join(words_name[i] for i in centroid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We notice the most used business names are very straight forword, telling the major business the entities are running.\n",
    "#### While I don't think these clusters are meaningful in distinguishing each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Cluster restaurants by tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### As we have data \"tip.json\", we can cluster the tips business entities to customers, to see whether different business entities emphasis different aspects of their business. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_business, file_checkin, file_review, file_tip, file_user = [\n",
    "    'dataset/business.json',\n",
    "    'dataset/checkin.json',\n",
    "    'dataset/review.json',\n",
    "    'dataset/tip.json',\n",
    "    'dataset/user.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>2012-07-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Get here early enough to have dinner.</td>\n",
       "      <td>zcTZk7OG8ovAmh_fenH21g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jH19V2I9fIslnNhDzPmdkA</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Great breakfast large portions and friendly wa...</td>\n",
       "      <td>ZcLKXikTHYOnYt5VYRO5sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2014-06-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice place. Great staff.  A fixture in the tow...</td>\n",
       "      <td>oaYhjqBbh18ZhU0bpyzSuw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Happy hour 5-7 Monday - Friday</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESzO3Av0b1_TzKOiqzbQYQ</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Parking is a premium, keep circling, you will ...</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k7WRPbDd7rztjHcGGkEjlw</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>Homemade pasta is the best in the area</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k7WRPbDd7rztjHcGGkEjlw</td>\n",
       "      <td>2017-04-08</td>\n",
       "      <td>0</td>\n",
       "      <td>Excellent service, staff is dressed profession...</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SqW3igh1_Png336VIb5DUA</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>0</td>\n",
       "      <td>Come early on Sunday's to avoid the rush</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNpcPGqDORDdvtekXd348w</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>0</td>\n",
       "      <td>Love their soup!</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNpcPGqDORDdvtekXd348w</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>0</td>\n",
       "      <td>Soups are fantastic!</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date  likes  \\\n",
       "0  tJRDll5yqpZwehenzE2cSg  2012-07-15      0   \n",
       "1  jH19V2I9fIslnNhDzPmdkA  2015-08-12      0   \n",
       "2  dAa0hB2yrnHzVmsCkN4YvQ  2014-06-20      0   \n",
       "3  dAa0hB2yrnHzVmsCkN4YvQ  2016-10-12      0   \n",
       "4  ESzO3Av0b1_TzKOiqzbQYQ  2017-01-28      0   \n",
       "5  k7WRPbDd7rztjHcGGkEjlw  2017-02-25      0   \n",
       "6  k7WRPbDd7rztjHcGGkEjlw  2017-04-08      0   \n",
       "7  SqW3igh1_Png336VIb5DUA  2016-07-03      0   \n",
       "8  KNpcPGqDORDdvtekXd348w  2016-01-07      0   \n",
       "9  KNpcPGqDORDdvtekXd348w  2016-05-22      0   \n",
       "\n",
       "                                                text                 user_id  \n",
       "0              Get here early enough to have dinner.  zcTZk7OG8ovAmh_fenH21g  \n",
       "1  Great breakfast large portions and friendly wa...  ZcLKXikTHYOnYt5VYRO5sg  \n",
       "2  Nice place. Great staff.  A fixture in the tow...  oaYhjqBbh18ZhU0bpyzSuw  \n",
       "3                     Happy hour 5-7 Monday - Friday  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "4  Parking is a premium, keep circling, you will ...  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "5             Homemade pasta is the best in the area  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "6  Excellent service, staff is dressed profession...  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "7           Come early on Sunday's to avoid the rush  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "8                                   Love their soup!  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "9                               Soups are fantastic!  ulQ8Nyj7jCUR8M83SUMoRQ  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_tip) as f:\n",
    "    df_tip = pd.DataFrame(json.loads(line) for line in f)\n",
    "df_tip.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1098325,), dtype('O'))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents = df_tip['text'].values\n",
    "documents.shape, documents.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split the data to training set and test set\n",
    "# Now your data is smaller, you can use a typical \"test_size\", e.g. 0.3-0.7\n",
    "documents_train, documents_test = train_test_split(\n",
    "    documents,\n",
    "test_size = 0.7, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer, choose a reasonable max_features, e.g. 1000\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 500)\n",
    "\n",
    "# Train the model with your training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train).toarray()\n",
    "\n",
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "# Use the trained model to transform all the reviews\n",
    "vectors_documents = vectorizer.transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit k-means clustering on the training vectors and make predictions on all data\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "\n",
    "kmeans.fit(vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on all data\n",
    "assigned_cluster = kmeans.predict(vectors_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 features for each cluster:\n",
      "0: great, food, service, place, staff, friendly, love, atmosphere, amazing, prices\n",
      "1: place, love, time, amazing, food, service, try, don, delicious, like\n",
      "2: awesome, food, service, place, great, staff, love, friendly, good, best\n",
      "3: best, town, ve, place, vegas, food, pizza, service, love, hands\n",
      "4: good, food, service, great, place, really, nice, pretty, friendly, prices\n"
     ]
    }
   ],
   "source": [
    "# Find the top 10 features for each cluster.\n",
    "top_n = 10\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:, -1:-(top_n+1):-1]\n",
    "print(\"top 10 features for each cluster:\")\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \", \".join(words[i] for i in centroid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  We notice that almost all business entities are using positive words in their tips, thus these clusters are not meaningful in distinguishing each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
